{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b948f366-2006-4f99-bee6-5a242000803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder  # label 수로 변환\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf786df4-fe76-419e-b3e3-69ef05aad3e3",
   "metadata": {},
   "source": [
    "## 참고 자료\n",
    "https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch\n",
    "https://gaussian37.github.io/dl-pytorch-neural-network/\n",
    "https://learn.microsoft.com/ko-kr/windows/ai/windows-ml/tutorials/pytorch-train-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6f4eb7-b821-48dd-b751-0b21f58f3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로\n",
    "path = 'C:\\\\Users\\\\JungHyeona\\\\Desktop\\\\KNN\\\\image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca722302-d55a-42c4-ad95-aef94117ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b487b956-6cb8-435d-8ea7-5729c6d92500",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for for_name in os.listdir(path):  # i = [\"AC\", \"FL\", \"HC\", \"HUM\"]\n",
    "    forder = os.path.join(path, for_name)  # ex) path/AC\n",
    "\n",
    "    for j in os.listdir(forder):\n",
    "        file = os.path.join(forder, j)  # ex) path/AC/a.png\n",
    "        \n",
    "        image = Image.open(file)\n",
    "        label = os.path.basename(os.path.dirname(file))\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b900efdc-8e5b-4ff3-9503-1bfd67586be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label값을 숫자로 변환해주기\n",
    "label_trans = {\"AC\" : 0, \"FL\" : 1, \"HC\" : 2, \"HUM\" : 3}\n",
    "labels = [label_trans[label] for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf0fc1-b61f-493e-899f-ed2c559d25e3",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a723e060-1da4-46c8-a94c-746538822485",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "     transforms.Resize((32, 32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((-0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7b325f-7434-491e-91ac-7884b58e3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 인스턴스 생성\n",
    "dataset = CustomDataset(images, labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74d8215c-0fbd-4414-ac20-6e9b80354d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 train, validation, test로 분리\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38771a91-08fb-458c-985e-f7a66cf34253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader를 통해 데이터를 불러올 수 있도록 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dadb64da-e1bf-45f2-8874-834f9ce2ce17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c2ea6d-af6e-493c-8ee0-b8a268004045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2249c6f8-6d07-4783-bd25-f81bc32b36dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# 이미지 크기 확인\n",
    "for batch, (X, y) in enumerate(train_loader):\n",
    "    print(batch)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969faca-60c6-40dc-bd05-92ed773156bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "838f3dc8-0667-4c96-9b24-51ac98bac611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a datas et with 10,000 samples.\n",
    "X, y = make_circles(n_samples = 10000,\n",
    "                    noise= 0.05,\n",
    "                    random_state=26)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd803493-a4e0-440f-9efe-9062a455eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.86143957,  0.51365619],\n",
       "       [ 0.15802293,  0.75413978],\n",
       "       [ 0.10045332, -1.02042385],\n",
       "       ...,\n",
       "       [-0.03391136, -0.79715534],\n",
       "       [-0.56320429,  0.88155148],\n",
       "       [ 0.94764034,  0.31432114]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5933543e-ef41-417f-80b7-f799b6ec0bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 2, 3, 3, 3, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print([train_dataset[-i][1] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efded2b7-87ae-401a-aa13-aa84d1399e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b9c3c1-8175-4224-8b98-f302c113d52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dcacdc0-c8d1-444b-a952-8d3c78cb8e90",
   "metadata": {},
   "source": [
    "### Neural Network 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bee6d0e-abca-4c2a-87c4-5d5b30e3c05c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.5071, -0.4946,  0.0399],\n",
      "        [-0.5402, -0.2331, -0.3610],\n",
      "        [ 0.3152,  0.5013,  0.1851],\n",
      "        [-0.0150, -0.2898,  0.4964],\n",
      "        [-0.3974, -0.0683, -0.5710],\n",
      "        [-0.5149, -0.3681, -0.4311],\n",
      "        [ 0.0793,  0.5364, -0.0754],\n",
      "        [ 0.2094,  0.4978,  0.2162],\n",
      "        [-0.0772,  0.2597, -0.0636],\n",
      "        [-0.0963, -0.5336, -0.3171],\n",
      "        [-0.3007,  0.4303, -0.5254],\n",
      "        [ 0.1989, -0.0021, -0.2080],\n",
      "        [ 0.2693, -0.3845, -0.2466],\n",
      "        [-0.3725,  0.0975, -0.5127],\n",
      "        [-0.3596, -0.1969, -0.2168],\n",
      "        [-0.1959, -0.1764, -0.2431],\n",
      "        [-0.5233, -0.0869,  0.3048],\n",
      "        [ 0.2132, -0.3506, -0.1781]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0462,  0.3969, -0.0921,  0.1233,  0.1943, -0.4459,  0.4148,  0.0579,\n",
      "        -0.5382, -0.1294, -0.2612, -0.1981, -0.2078,  0.0231,  0.3558, -0.3537,\n",
      "         0.4587,  0.5065], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2070,  0.2053, -0.2113, -0.1816,  0.0432, -0.0675, -0.0789, -0.1299,\n",
      "         -0.1878,  0.2093, -0.0824, -0.0040, -0.1783,  0.1751,  0.0137,  0.0110,\n",
      "         -0.2340,  0.2236],\n",
      "        [-0.1391, -0.1155,  0.0085, -0.0708, -0.1070,  0.1194, -0.1477, -0.1956,\n",
      "         -0.0525,  0.1938, -0.0908,  0.0568,  0.0179,  0.0447, -0.2013, -0.2213,\n",
      "         -0.0161,  0.0329],\n",
      "        [-0.1081,  0.0900,  0.1443, -0.2065, -0.2112,  0.0585,  0.2333, -0.0221,\n",
      "         -0.0467, -0.0751, -0.0973,  0.0252,  0.0121, -0.1710,  0.1572,  0.0627,\n",
      "         -0.1454, -0.1710],\n",
      "        [-0.0363, -0.0367, -0.1487,  0.1924, -0.1910, -0.1987,  0.0449, -0.1111,\n",
      "         -0.0946,  0.1931,  0.1877,  0.2296,  0.1183,  0.2259,  0.0297, -0.0938,\n",
      "         -0.1543,  0.0831]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0195, 0.0917, 0.2052, 0.0615], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    # 신경망 layer 구성요소 정의\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear01 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear02 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.linear01(x))\n",
    "        x = F.relu(self.linear02(x))\n",
    "\n",
    "        return x\n",
    "        \n",
    "model = NN(32*32, 18, 4)\n",
    "# 학습하기 전의 weight와 bias를 출력합니다.\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760a6a6c-214b-40c3-b8fa-2c3411e6d2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (linear01): Linear(in_features=3, out_features=18, bias=True)\n",
       "  (linear02): Linear(in_features=18, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 사용 가능 여부에 따라 디바이스 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f6de9-2dd7-4506-92bd-355cb7454a30",
   "metadata": {},
   "source": [
    "### 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57080747-0a1f-4e45-9c46-607d80b2bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0002\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f83ccba4-2e8a-4acc-9c73-72e97e4f2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 27\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e81fcdc5-e678-4290-a4d9-7ff7c7518897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3072x32 and 3x18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4416\\4185889198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# 예측과 손실 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mm_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4416\\3623153334.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear01\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear02\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3072x32 and 3x18)"
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "avg_cost = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    \n",
    "    # 미니 배치 단위로 꺼내온다.\n",
    "    for X, Y in train_loader: \n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        # 파라미터(가중치) 0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 예측과 손실 계산\n",
    "        m_pred = model(X)\n",
    "        loss = loss_func(m_pred, Y)\n",
    "        loss_values.append(loss.item())\n",
    "        \n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        # 경사 갱신\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += loss / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644288b9-dd43-4610-a1f2-d8e89aaaca07",
   "metadata": {},
   "source": [
    "### 모델 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd449c88-8331-4e53-9008-5721509507e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5098127-4000-4a90-81a9-f45a884fa123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "val_accuracy = evaluate(model, val_loader, device)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b2c04-d30a-46d5-8bd9-d50afb80c6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dda241-740d-4266-970c-3b01e6c48141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "159c46bf-c41f-4691-962e-b647d3f8a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6662b5a2-468e-4f08-ad61-09223402db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  80.,  75.],\n",
       "        [ 93.,  88.,  93.],\n",
       "        [ 89.,  91.,  90.],\n",
       "        [ 96.,  98., 100.],\n",
       "        [ 73.,  66.,  70.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db887b8-8875-4676-8b0c-3addb90560e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
